{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27e39fd-b9f8-4273-83fe-d40d8e6ec9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb83e64-9612-4529-92c5-a7ef8bcb343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa1d979-6d2b-41af-9b12-8d5c19eea385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    file_path = 'data_files/BBC News Train.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset not found!!!! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1720d54-4096-4ff4-95cb-4f64ee484fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ArticleId                                               Text  Category\n",
      "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
      "1        154  german business confidence slides german busin...  business\n",
      "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
      "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
      "4        917  enron bosses in $168m payout eighteen former e...  business\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals():\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2034f0db-7c9f-4dac-acad-fbb9536c35d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44316ebb-6c67-4d1b-b3be-8ec8e982bed5",
   "metadata": {},
   "source": [
    "##### Preprocess for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eb06e34-2666-4a3d-aac9-54f5924b7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7253f376-ad35-40e1-ab03-698f71ee6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_w2v(text):\n",
    "    \"\"\"\n",
    "    Prepares text for Word2Vec:\n",
    "    1. Tokenize\n",
    "    2. Lowercase\n",
    "    3. Remove punctuation\n",
    "    4. Remove stop words\n",
    "    5. Remove short words (<= 2 chars)\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    processed_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        if (token not in stop_words and\n",
    "            token not in string.punctuation and\n",
    "            token.isalpha()): # Remove numbers\n",
    "            \n",
    "            if len(token) > 2:\n",
    "                processed_tokens.append(token)\n",
    "                \n",
    "    return processed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1fc753b-c9db-4635-8c96-c08f90ea7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting text preprocessing for Word2Vec...\n",
      "Preprocessing complete.\n",
      "\n",
      "--- Example Processed Document (as a list of tokens) ---\n",
      "['worldcom', 'launches', 'defence', 'lawyers', 'defending', 'former', 'worldcom', 'chief', 'bernie', 'ebbers', 'battery', 'fraud', 'charges', 'called', 'company', 'whistleblower', 'first', 'witness', 'cynthia', 'cooper']\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"\\nStarting text preprocessing for Word2Vec...\")\n",
    "    \n",
    "    # Apply the preprocessing to all documents\n",
    "    corpus = [preprocess_text_w2v(doc) for doc in df['Text']]\n",
    "    \n",
    "    print(\"Preprocessing complete.\")\n",
    "    \n",
    "    # Print an example (first 20 tokens of the first doc)\n",
    "    print(\"\\n--- Example Processed Document (as a list of tokens) ---\")\n",
    "    print(corpus[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8cf7e-36fb-4463-a405-007735638c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46528e82-803a-49b9-8d04-d0efe7a5994f",
   "metadata": {},
   "source": [
    "##### Train the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed306e26-d18e-4cf5-be4f-fa8afaef32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Word2Vec model...\n",
      "Model training complete.\n",
      "\n",
      "Vocabulary size: 8076 words\n"
     ]
    }
   ],
   "source": [
    "if 'corpus' in locals():\n",
    "    print(\"\\nTraining Word2Vec model...\")\n",
    "    \n",
    "    # Train the model\n",
    "    # Key parameters:\n",
    "    # - corpus: Our list of lists\n",
    "    # - vector_size: The dimensionality of the word vector (100 is a good default)\n",
    "    # - window: The max distance between a target word and its neighbors (5)\n",
    "    # - min_count: Ignores all words with a total frequency lower than this (5)\n",
    "    # - workers: Number of CPU cores to use (4)\n",
    "    model = Word2Vec(\n",
    "        sentences=corpus,\n",
    "        vector_size=100,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        workers=4\n",
    "    )\n",
    "    \n",
    "    print(\"Model training complete.\")\n",
    "    print(f\"\\nVocabulary size: {len(model.wv.key_to_index)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f4c3-0400-4d5d-9f53-d16bc2057ade",
   "metadata": {},
   "source": [
    "##### Explore the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd68478-e5e0-4a50-9db8-26ce6bab8f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Most similar to 'government' ---\n",
      "[('said', 0.9788783192634583), ('party', 0.9665631651878357), ('labour', 0.9626592397689819), ('tory', 0.9620104432106018), ('tories', 0.9597377777099609)]\n",
      "\n",
      "--- Most similar to 'sport' ---\n",
      "[('programme', 0.9977071285247803), ('today', 0.9939746260643005), ('correspondent', 0.992902398109436), ('website', 0.9894682168960571), ('reporters', 0.9870164394378662)]\n",
      "\n",
      "--- Most similar to 'music' ---\n",
      "[('digital', 0.9752787351608276), ('video', 0.9565134644508362), ('phones', 0.9436734318733215), ('phone', 0.9340487718582153), ('technology', 0.9312829375267029)]\n",
      "\n",
      "--- Which word doesn't match? ---\n",
      "Outlier in ['film', 'music', 'show', 'election']: election\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    \n",
    "    # --- 1. Find Most Similar Words ---\n",
    "    # Check words related to the dataset's topics\n",
    "    \n",
    "    print(\"\\n--- Most similar to 'government' ---\")\n",
    "    try:\n",
    "        print(model.wv.most_similar('government', topn=5))\n",
    "    except KeyError:\n",
    "        print(\"'government' not in vocabulary (or failed min_count).\")\n",
    "\n",
    "    print(\"\\n--- Most similar to 'sport' ---\")\n",
    "    try:\n",
    "        print(model.wv.most_similar('sport', topn=5))\n",
    "    except KeyError:\n",
    "        print(\"'sport' not in vocabulary.\")\n",
    "        \n",
    "    print(\"\\n--- Most similar to 'music' ---\")\n",
    "    try:\n",
    "        print(model.wv.most_similar('music', topn=5))\n",
    "    except KeyError:\n",
    "        print(\"'music' not in vocabulary.\")\n",
    "\n",
    "    # --- 2. Find the Outlier ---\n",
    "    print(\"\\n--- Which word doesn't match? ---\")\n",
    "    try:\n",
    "        # The model should identify 'election' as the outlier\n",
    "        outlier = model.wv.doesnt_match(['film', 'music', 'show', 'election'])\n",
    "        print(f\"Outlier in ['film', 'music', 'show', 'election']: {outlier}\")\n",
    "    except KeyError:\n",
    "        print(\"One or more words not in vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2f757-6e64-4cb0-a268-30f9ec9d474e",
   "metadata": {},
   "source": [
    "##### The Analogy Task (Vector Arithmetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b431e83-0a6e-4961-b24b-37599798af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analogy Task ---\n",
      "king - man + woman = [('started', 0.9987601041793823)]\n",
      "\n",
      "britain - london + paris = [('run', 0.9950436353683472)]\n",
      "Skipping 'he/man/woman' analogy, words not in vocab.\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    print(\"\\n--- Analogy Task ---\")\n",
    "    \n",
    "    # Analogy 1: king - man + woman = ?\n",
    "    try:\n",
    "        result = model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "        print(f\"king - man + woman = {result}\")\n",
    "    except KeyError:\n",
    "        print(\"Skipping 'king/man/woman' analogy, words not in vocab.\")\n",
    "\n",
    "    # Let's try an analogy that's more likely to be in our dataset\n",
    "    # Analogy 2: britain - london + paris = ? (Should be 'france')\n",
    "    try:\n",
    "        result = model.wv.most_similar(positive=['britain', 'paris'], negative=['london'], topn=1)\n",
    "        print(f\"\\nbritain - london + paris = {result}\")\n",
    "    except KeyError:\n",
    "        print(\"Skipping 'britain/london/paris' analogy, words not in vocab.\")\n",
    "        \n",
    "    # Analogy 3: he - man + woman = ? (Should be 'she')\n",
    "    try:\n",
    "        result = model.wv.most_similar(positive=['he', 'woman'], negative=['man'], topn=1)\n",
    "        print(f\"\\nhe - man + woman = {result}\")\n",
    "    except KeyError:\n",
    "        print(\"Skipping 'he/man/woman' analogy, words not in vocab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5665b-9140-45a1-97f8-cc919945a199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594ab08-f94b-4d0d-a109-9c8a44547fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590a973-5394-4098-9e82-9b37d90d7387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ebd2a-aa49-430d-b216-4148060b572a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafd477-81eb-47b9-ab22-d3f9e03fb59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
